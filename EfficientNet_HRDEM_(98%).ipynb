{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BillXu21/culvert-identification/blob/main/EfficientNet_HRDEM_(98%25).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb9mOho-4Jzu"
      },
      "outputs": [],
      "source": [
        " #!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4-tHPbV7Yz7",
        "outputId": "59e580d3-ca65-4c30-e8d8-df88ec3cdca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1aSvmuWO8gT",
        "outputId": "0f989975-060b-4107-db1b-b9e53a828ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IitySReDO9VA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "from skimage import io\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import tensorflow as tf\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.compat.v1.keras.models import Sequential\n",
        "from tensorflow.compat.v1.keras.layers import BatchNormalization\n",
        "from tensorflow.compat.v1.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.compat.v1.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.compat.v1.keras.optimizers import Adadelta, Adam\n",
        "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#from tensorflow.keras import callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlHDhDKcPCnP"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/WFBBDEM/'   #DEM\n",
        "\n",
        "# using one watershed to train model, 3 of them to test\n",
        "pathTrain='WFBBDEM_Train/'\n",
        "pathTest1='WFBBDEM_Test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_9MeDbA94s6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1dZM1okU_Ay"
      },
      "outputs": [],
      "source": [
        "# # read all images\n",
        "# import rasterio as rio\n",
        "# def read_img(path):\n",
        "#     cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)] # get F,T folder\n",
        "#     imgs=[]\n",
        "#     labels=[]\n",
        "#     imgs_name=[]\n",
        "#     cate = cate[:2]\n",
        "#     for idx,folder in enumerate(cate): # idx-> 0:F; 1:T; folder-> F,T\n",
        "#         for im in glob.glob(folder+\"/*.tif\"):\n",
        "#             im = im.replace('\\\\','/')\n",
        "# #            print('reading the images:%s'%(im))\n",
        "\n",
        "#             img_name=os.path.basename(im)\n",
        "#             img_name=os.path.splitext(img_name)[0] # get file name\n",
        "\n",
        "#             #img=io.imread(im)\n",
        "#             with rio.open(im) as i:\n",
        "#               img = i.read()\n",
        "#             # Normalize the dataset-MaxMin\n",
        "#             img = np.squeeze(img)\n",
        "#             scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#             img = scaler.fit_transform(img)\n",
        "\n",
        "#             imgs.append(img)\n",
        "#             labels.append(idx)\n",
        "#             imgs_name.append(img_name) # image name\n",
        "\n",
        "#     return np.asarray(imgs,np.float32),np.asarray(labels,np.int32), np.asarray(imgs_name)\n",
        "\n",
        "# data,label,name=read_img(path+pathTrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4NVfVChYbUw"
      },
      "outputs": [],
      "source": [
        "#### Test data-3 watersheds\n",
        "#dataTst1, labelTst1, nameTst1 =read_img(path+pathTest1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/data','wb') as fin: pickle.dump(data,fin)\n",
        "# with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/label','wb') as fin: pickle.dump(label,fin)\n",
        "# with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/name','wb') as fin: pickle.dump(name,fin)"
      ],
      "metadata": {
        "id": "GHa-R4jfxEfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/data','rb') as fin: data = pickle.load(fin)\n",
        "with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/label','rb') as fin: label = pickle.load(fin)\n",
        "with open('/content/drive/MyDrive/WFBBDEM/CNN_Train/name','rb') as fin: name = pickle.load(fin)"
      ],
      "metadata": {
        "id": "R2l3OoRIwGJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfMMT_xBus7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYP4P6g30exU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ggf632H0Ym7"
      },
      "outputs": [],
      "source": [
        "#data=np.expand_dims(data,3) # add channel dimension, 4D\n",
        "data = np.repeat(data[..., np.newaxis], 3, -1)\n",
        "\n",
        "labelN=label.shape[0]\n",
        "\n",
        "\n",
        "label_name=np.empty((labelN,2),dtype=int) # label + name\n",
        "for i in range(labelN):\n",
        "    label_name[i,0]=label[i] # label\n",
        "    if (name[i].isdigit()):\n",
        "        name[i]=name[i]\n",
        "    else:\n",
        "        name[i]=name[i][1:] # only keep number, delete first letter\n",
        "    name[i] = name[i].split()[0]\n",
        "    label_name[i,1]=name[i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BImPttew4NXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lemifhYU0afw"
      },
      "outputs": [],
      "source": [
        "# dataTst1=np.expand_dims(dataTst1,3)\n",
        "# ######Test1\n",
        "# labelN_Tst1=labelTst1.shape[0]\n",
        "\n",
        "# label_nameTst1=np.empty((labelN_Tst1,2),dtype=int) # label + name\n",
        "# for i in range(labelN_Tst1):\n",
        "#     label_nameTst1[i,0]=labelTst1[i] # label\n",
        "#     if (nameTst1[i].isdigit()):\n",
        "#         nameTst1[i]=nameTst1[i]\n",
        "#     else:\n",
        "#         nameTst1[i]=nameTst1[i][1:] # only keep number, delete first letter\n",
        "#     label_nameTst1[i,1]=nameTst1[i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xpo9wk9v4Wjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp57KNqaBd0Z"
      },
      "outputs": [],
      "source": [
        "# split data into train and test groups\n",
        "train_data,test_data,train_label,test_label = train_test_split(data,label_name,test_size=0.2,stratify=label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXaahe785AIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ9QJ7MKFbUM"
      },
      "outputs": [],
      "source": [
        "# creat CNN model\n",
        "def createCNN():\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    model.add(Convolution2D(128, 3, 3, padding=\"same\", input_shape=(100, 100, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "#    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.30))\n",
        "\n",
        "\n",
        "    model.add(Convolution2D(256, (3,3), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "#    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.30))\n",
        "\n",
        "\n",
        "    model.add(Convolution2D(512, (5,5), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "#    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.30))\n",
        "\n",
        "\n",
        "    model.add(Convolution2D(1024, (5,5), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "#    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.30))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSCjJkfH2GFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IvCqRb7Hi_W",
        "outputId": "a5f8c405-bbea-4726-c6c8-413e74a9b45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "LEARNING_RATE = 1e-6\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "model = tf.keras.applications.EfficientNetV2M(\n",
        "    weights='/content/drive/MyDrive/WFBBDEM/Models/ModelDEM2022EfficientNetM.h5',\n",
        "    include_top=True,\n",
        "    input_tensor=None,\n",
        "    input_shape=(100,100,3),\n",
        "    pooling=\"max\",\n",
        "    classes = 2,\n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "\n",
        "# classification_head = keras.Sequential(\n",
        "#     [\n",
        "#         keras.layers.Dense(2, activation='softmax')\n",
        "#     ],\n",
        "#     name='classification_head'\n",
        "# )\n",
        "\n",
        "# #x = neck_branch(model.output)\n",
        "# output_a = classification_head(model.output)\n",
        "# model = keras.Model(model.inputs, [output_a])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=LEARNING_RATE),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEvOhh6Q2X17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "aTgSdRtFtNKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD0NF7XK5nFf",
        "outputId": "39859ed4-7f80-4544-a822-c19b49c9e498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNTZfDiiHmij",
        "outputId": "a82fdeff-81ff-469e-94e1-e9db99953d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 2324 samples, validate on 582 samples\n",
            "Epoch 1/10\n",
            "2324/2324 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.9600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97079, saving model to /content/drive/MyDrive/WFBBDEM/Models/ModelDEM2022EfficientNetM1.h5\n",
            "2324/2324 [==============================] - 614s 264ms/sample - loss: 0.1859 - accuracy: 0.9600 - val_loss: 0.1412 - val_accuracy: 0.9708\n",
            "Epoch 2/10\n",
            "2324/2324 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9617\n",
            "Epoch 2: val_accuracy did not improve from 0.97079\n",
            "2324/2324 [==============================] - 25s 11ms/sample - loss: 0.1687 - accuracy: 0.9617 - val_loss: 0.1331 - val_accuracy: 0.9691\n",
            "Epoch 3/10\n",
            "1536/2324 [==================>...........] - ETA: 7s - loss: 0.1575 - accuracy: 0.9616"
          ]
        }
      ],
      "source": [
        "OUT_DIR = \"/content/drive/MyDrive/WFBBDEM/Models\"\n",
        "checkpoint = ModelCheckpoint(os.path.join(OUT_DIR, 'ModelDEM2022EfficientNetM1.h5'),  # model filename\n",
        "                              monitor='val_accuracy', # quantity to monitor\n",
        "                              verbose=1, # verbosity - 0 or 1\n",
        "                              save_best_only= True, # The latest best model will not be overwritten\n",
        "                              save_weights_only=True, # save model, not only weights\n",
        "                              mode='auto') # The decision to overwrite model is made\n",
        "                                            # automatically depending on the quantity to monitor\n",
        "\n",
        "model_details = model.fit(train_data, train_label[:,0],\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          epochs = EPOCHS,\n",
        "                          validation_split=0.2,\n",
        "                          callbacks=[checkpoint],\n",
        "                          verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VNDq1hGOQil"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex6ka4STZSgC"
      },
      "outputs": [],
      "source": [
        "scroe, accuracy = model.evaluate(test_data, test_label[:,0], batch_size=BATCH_SIZE)\n",
        "print('EfficientNet_Test: loss:', scroe, 'accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtkAhGVC_YgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0B_go4RZTCe"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "pred_label = model.predict(test_data)\n",
        "print(pred_label)\n",
        "pred_label = np.argmax(pred_label, axis=1)\n",
        "\n",
        "\n",
        "for t in range(pred_label.shape[0]):\n",
        "    NameWrong=[]\n",
        "    labelPred=[]\n",
        "    if (pred_label[t]!=test_label[t,0]):\n",
        "        # print (test_label[t,0], test_label[t,1], pred_label[t])\n",
        "        NameWrong.append(test_label[t,1])\n",
        "        labelPred.append(pred_label[t])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kA66F91aUYAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUH4R3oRZVm4"
      },
      "outputs": [],
      "source": [
        "#### plot confusion matrix\n",
        "def plot_confusion_matrix(confusion_mat):\n",
        "    plt.imshow(confusion_mat,interpolation='nearest',cmap=plt.cm.Wistia)\n",
        "    plt.title('CNN Confusion Matrix',fontsize=20)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(2) # class number\n",
        "    plt.xticks(tick_marks,tick_marks,fontsize=16)\n",
        "    plt.yticks(tick_marks,tick_marks,fontsize=16)\n",
        "    plt.ylabel('True Label',fontsize=16)\n",
        "    plt.xlabel('Predicted Label',fontsize=16)\n",
        "    for i in range(len(confusion_mat)):    #row\n",
        "        for j in range(len(confusion_mat[i])):    #col\n",
        "            plt.text(j, i, confusion_mat[i][j],fontsize=16) # images number of each part\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "confusion_matrix = tf.math.confusion_matrix(labels=test_label[:,0],predictions=pred_label, num_classes=2, dtype=tf.int32, name=None, weights=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43-Eb-BeZYZ4"
      },
      "outputs": [],
      "source": [
        "sess=tf.compat.v1.Session()\n",
        "\n",
        "#with tf.compat.v1.Session(graph=g) as sess:\n",
        "confusion_matrix = sess.run(confusion_matrix)\n",
        "plot_confusion_matrix(confusion_matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NztcdyxBZZwz"
      },
      "outputs": [],
      "source": [
        "######################### learning curve\n",
        "\n",
        "def plot_learning_curves(history):\n",
        "    df=pd.DataFrame(history.history,index=np.arange(0, EPOCHS).astype(dtype=np.str))\n",
        "    df.plot(use_index=True,figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "\n",
        "    #plt.gca().set_ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(model_details)\n",
        "\n",
        "print ('Accuracy:', '{:.4f}'.format(accuracy), 'Batch Size:', BATCH_SIZE,'Learning Rate:', LEARNING_RATE, 'Epochs:', EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-WC1nqj5N0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX4_QRw3ZbPz"
      },
      "outputs": [],
      "source": [
        "# ########################################### Test\n",
        "\n",
        "# ################Test1\n",
        "\n",
        "# scroeTst1, accuracyTst1 = model.evaluate(dataTst1,label_nameTst1[:,0], batch_size=BATCH_SIZE)\n",
        "# print('CNN_Test_Test1: loss:', scroeTst1, 'accuracy:', accuracyTst1)\n",
        "\n",
        "# # Predict\n",
        "# pred_labelTst1 = model.predict(dataTst1)\n",
        "# pred_labelTst1 = np.argmax(pred_labelTst1, axis=1)\n",
        "\n",
        "\n",
        "# for t1 in range(pred_labelTst1.shape[0]):\n",
        "#     NameWrongTst1=[]\n",
        "#     labelPredTst1=[]\n",
        "#     if (pred_labelTst1[t1]!=label_nameTst1[t1,0]):\n",
        "#         NameWrongTst1.append(label_nameTst1[t1,1])\n",
        "#         labelPredTst1.append(pred_labelTst1[t1])\n",
        "\n",
        "# # np.save(\"D:/CNNtest2022/ResultName/NameWrongTst1.npy\",NameWrongTst1,save_format='h5') # names of wrongly classified images\n",
        "# # np.save(\"D:/CNNtest2022/ResultName/LabelPredTst1.npy\",labelPredTst1,save_format='h5')\n",
        "\n",
        "\n",
        "\n",
        "# # Confusion matrix\n",
        "# confusion_matrix_Tst1 = tf.math.confusion_matrix(labels=label_nameTst1[:,0],predictions=pred_labelTst1, num_classes=None, dtype=tf.int32, name=None, weights=None)\n",
        "# # sess=tf.compat.v1.Session()\n",
        "# sess_Tst1=tf.compat.v1.Session()\n",
        "\n",
        "# #with tf.compat.v1.Session(graph=g) as sess:\n",
        "# confusion_matrix_Tst1 = sess_Tst1.run(confusion_matrix_Tst1)\n",
        "# plot_confusion_matrix(confusion_matrix_Tst1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Am-BW0ZeSw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}